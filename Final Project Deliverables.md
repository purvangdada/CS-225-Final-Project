CS225 Final Project:
muthuga2-tinreyd2-pdada2-thm2
GOALS:
Leading Question: Our team has decided to utilize the Open Flights dataset. We are hoping to use our algorithms to better understand the relationship between various airports. Through our use of the algorithms to find the betweenness centrality and graph coloring, we will be able to discover which airports are the most popular and how these airports connect with one another.
Dataset Acquisition and Processing: We plan to use the planes.dat and routes.dat for the project. We discovered that these datasets are most relevant when it comes to finding out how different airports interact with each other. These datasets also best complement the graph algorithms we plan to use to show the relationship between a said number of airports.
Graph Algorithms: The graph algorithms we plan to use for the project include Betweenness Centrality and Graph Coloring. These algorithms will take in the airports as the input nodes, and the flights between them as the input edges. Betweenness centrality will also use the distances between the airports to weight the graph. Betweenness centrality will produce an output graph that represents how necessary an airport is in connecting flights in the shortest paths. Graph coloring will produce an output graph that shows which airports have directly linking flights and which do not and require interconnecting flights. Since for betweenness centrality we essentially have to travel over every edge for each vertex pair in order to find the shortest path, and there are a number of vertex pairs equal to number of vertices squared minus the number of vertices, I would expect a time complexity around O((V^2)E). Though this is not exact because some edges may not be travelled while other edges may be travelled over multiple times for any given shortest path calculation. For graph coloring, each vertex will be examined once along with each of its edges, which I would expect to result in a time complexity around O(V+2E).
Timeline: The first thing we must do is acquire and process our data set so that we can access and manipulate it with our algorithms. It is our goal to have done this by November 20. It is then our goal to have successfully implemented a BFS traversal of this data by November 29, so it is done before the mid-project check-in, and also have gotten started on our algorithms at this point, at least having a solid understanding of how we will implement them. We will hope to then implement our betweenness centrality and graph coloring algorithms over the next two weeks, doing whichever we determine to be simpler first so that we have more time to tackle the more complex algorithm.
Development:
Week of December 5, 2021:
This week, we created a shell of our eventual program. We created a basic node and edge class. We used airports as the nodes of our graph and the routes as the edges with direction. Furthermore, we implemented the Haversine formula to calculate distance based on longitude and latitude. This week we also started developing our breadth first traversal.

Week of December 12, 2021
During this week, we completed our BFS and began working on our algorithms. We fully implemented the Betweenness Centrality algorithm and our Graph Coloring algorithm. We then began trying to draw out our graph. As we were working on our algorithms, we were also developing our test suite to include our node and edge functions, our BFS, and eventually our algorithms.
 
RESULTS:
We were able to create our algorithms and a test suite to go along with them. We created a significantly smaller set of airports and routes to more quickly and efficiently test our algorithms. We also made sure to test our fundamental functions such as file reading and parsing lines of CSV. These tests truly helped us during our development process in debugging. Once we completed our project, our understanding of the connection of airports was enhanced. It was very interesting to see the web of nodes and edges that represented airports drawn out.
We did find that betweenness centrality takes far too long to run on the full dataset, so unfortunately we had to use a smaller portion to see it in action, but it was very cool to see how large some nodes were compared to how tiny others were.
It was also interesting that it seemed like many smaller nodes were often the same color, while larger nodes would take a different color, probably because large nodes receive more traffic and as such cannot share a color with as many nodes.
Ultimately, we were able to produce functioning versions of all of our proposed goals. Tests for all of our functions are passed successfully, and drawing the graphs produces a legible and interesting image.
Some of the interesting discoveries we made were that the datasets we had sometimes referred to nonexistent airports or other oddities we had to account for, or in betweenness centrality, we had to make a shortest path algorithm, but Dijkstra's algorithm was not sufficient for our dataset. We had to account for the possibility of revisiting visited nodes if it resulted in a shorter path, so instead of deciding where to visit based on whether its been visited, we only visited nodes that would produce a shorter path than we already had. This also prevented looping.
It was also quite difficult to graph betweenness centrality because of how long it takes in addition to the massive betweenness centrality values produced. These massive values made it difficult to implement sizes for the nodes where the biggest nodes weren't to big and the smallest nodes weren't too small, but there was still a visible spectrum of size.
Another interesting thing is that there is no optimal graph coloring algorithm, so our arbitrary ordering using BFT could be a very effective or ineffective coloring. Hopefully its the former.
